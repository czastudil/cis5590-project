{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853720bd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac3cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cindyzastudil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/cindyzastudil/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cindyzastudil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d4398",
   "metadata": {},
   "source": [
    "## Read in the CMU Book Summary Dataset\n",
    "\n",
    "The CMU Book Summary Dataset is a collection of 16,559 different book summaries extracted from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48849602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       title  \\\n",
      "0                                Animal Farm   \n",
      "1                         A Clockwork Orange   \n",
      "2                                 The Plague   \n",
      "3  An Enquiry Concerning Human Understanding   \n",
      "4                       A Fire Upon the Deep   \n",
      "\n",
      "                                               genre  \\\n",
      "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
      "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
      "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
      "3                                                NaN   \n",
      "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
      "\n",
      "                                             summary  \n",
      "0   Old Major, the old boar on the Manor Farm, ca...  \n",
      "1   Alex, a teenager living in near-future Englan...  \n",
      "2   The text of The Plague is divided into five p...  \n",
      "3   The argument of the Enquiry proceeds by a ser...  \n",
      "4   The novel posits that space around the Milky ...  \n"
     ]
    }
   ],
   "source": [
    "# Read in the data and add columns to the dataframe\n",
    "book_summs = pd.read_csv('data/booksummaries.txt', header=None, sep='\\t')\n",
    "book_summs.columns =['wikipedia_article_id', 'freebase_id', 'title', 'author', 'pub_date', 'genre', 'summary']\n",
    "\n",
    "# Remove extraneous features - wikipedia_article_id, freebase_id, author, pub_date\n",
    "book_summs = book_summs.drop(labels=['wikipedia_article_id', 'freebase_id', 'author', 'pub_date'], axis=1)\n",
    "print(book_summs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e6030",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a37027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code taken from fast-bert\n",
    "def spec_add_spaces(t: str) -> str:\n",
    "    \"Add spaces around / and # in `t`. \\n\"\n",
    "    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\n",
    "\n",
    "def rm_useless_spaces(t: str) -> str:\n",
    "    \"Remove multiple spaces in `t`.\"\n",
    "    return re.sub(\" {2,}\", \" \", t)\n",
    "\n",
    "def replace_multi_newline(t: str) -> str:\n",
    "    return re.sub(r\"(\\n(\\s)*){2,}\", \"\\n\", t)\n",
    "\n",
    "def clean_text(input_text):\n",
    "    text = replace_multi_newline(input_text)\n",
    "    text = spec_add_spaces(text)\n",
    "    text = rm_useless_spaces(text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f4dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset before preprocessing: 16559\n",
      "Size of dataset after removing missing genres: 12841\n",
      "Size of dataset after removing missing titles: 12841\n",
      "Size of dataset after removing missing summaries: 12841\n",
      "Size of dataset after preprocessing: 12841\n",
      "                            title  \\\n",
      "0                     Animal Farm   \n",
      "1              A Clockwork Orange   \n",
      "2                      The Plague   \n",
      "4            A Fire Upon the Deep   \n",
      "5  All Quiet on the Western Front   \n",
      "\n",
      "                                               genre  \\\n",
      "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
      "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
      "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
      "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
      "5  {\"/m/098tmk\": \"War novel\", \"/m/016lj8\": \"Roman...   \n",
      "\n",
      "                                             summary          tokenized_title  \\\n",
      "0   Old Major, the old boar on the Manor Farm, ca...           [animal, farm]   \n",
      "1   Alex, a teenager living in near-future Englan...      [clockwork, orange]   \n",
      "2   The text of The Plague is divided into five p...                 [plague]   \n",
      "4   The novel posits that space around the Milky ...       [fire, upon, deep]   \n",
      "5   The book tells the story of Paul Bäumer, a Ge...  [quiet, western, front]   \n",
      "\n",
      "                                   tokenized_summary  \n",
      "0  [old, major, ,, old, boar, manor, farm, ,, cal...  \n",
      "1  [alex, ,, teenager, living, near-future, engla...  \n",
      "2  [text, plague, divided, five, parts, ., town, ...  \n",
      "4  [novel, posits, space, around, milky, way, div...  \n",
      "5  [book, tells, story, paul, bäumer, ,, german, ...  \n"
     ]
    }
   ],
   "source": [
    "print('Size of dataset before preprocessing:', len(book_summs))\n",
    "\n",
    "# Remove any books which don't have genres\n",
    "book_summs.dropna(subset=['genre'], inplace=True)\n",
    "\n",
    "print('Size of dataset after removing missing genres:', len(book_summs))\n",
    "\n",
    "# Remove any books which don't have titles\n",
    "book_summs.dropna(subset=['title'], inplace=True)\n",
    "\n",
    "print('Size of dataset after removing missing titles:', len(book_summs))\n",
    "\n",
    "# Remove any books which don't have summaries\n",
    "book_summs.dropna(subset=['summary'], inplace=True)\n",
    "\n",
    "print('Size of dataset after removing missing summaries:', len(book_summs))\n",
    "print('Size of dataset after preprocessing:', len(book_summs))\n",
    "\n",
    "# Tokenize titles & convert to lower case - add to tokenized_title column\n",
    "book_summs['tokenized_title'] = book_summs['title'].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "\n",
    "# Tokenize summaries & convert to lower case - add to tokenized_summary column\n",
    "book_summs['tokenized_summary'] = book_summs['summary'].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "\n",
    "# Remove all stop words from all summaries & titles\n",
    "stop = stopwords.words('english')\n",
    "book_summs['tokenized_summary'] = book_summs['tokenized_summary'].apply(lambda x: [word for word in x if word not in (stop)])\n",
    "book_summs['tokenized_title'] = book_summs['tokenized_title'].apply(lambda x: [word for word in x if word not in (stop)])\n",
    "    \n",
    "print(book_summs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6029cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            title  \\\n",
      "0                     Animal Farm   \n",
      "1              A Clockwork Orange   \n",
      "2                      The Plague   \n",
      "4            A Fire Upon the Deep   \n",
      "5  All Quiet on the Western Front   \n",
      "\n",
      "                                               genre  \\\n",
      "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
      "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
      "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
      "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
      "5  {\"/m/098tmk\": \"War novel\", \"/m/016lj8\": \"Roman...   \n",
      "\n",
      "                                             summary          tokenized_title  \\\n",
      "0   Old Major, the old boar on the Manor Farm, ca...           [animal, farm]   \n",
      "1   Alex, a teenager living in near-future Englan...      [clockwork, orange]   \n",
      "2   The text of The Plague is divided into five p...                 [plague]   \n",
      "4   The novel posits that space around the Milky ...       [fire, upon, deep]   \n",
      "5   The book tells the story of Paul Bäumer, a Ge...  [quiet, western, front]   \n",
      "\n",
      "                                   tokenized_summary  \\\n",
      "0  [old, major, ,, old, boar, manor, farm, ,, cal...   \n",
      "1  [alex, ,, teenager, living, near-future, engla...   \n",
      "2  [text, plague, divided, five, parts, ., town, ...   \n",
      "4  [novel, posits, space, around, milky, way, div...   \n",
      "5  [book, tells, story, paul, bäumer, ,, german, ...   \n",
      "\n",
      "                                     formatted_genre  \n",
      "0  [Roman à clef, Satire, Children's literature, ...  \n",
      "1  [Science Fiction, Novella, Speculative fiction...  \n",
      "2  [Existentialism, Fiction, Absurdist fiction, N...  \n",
      "4  [Hard science fiction, Science Fiction, Specul...  \n",
      "5                          [War novel, Roman à clef]  \n"
     ]
    }
   ],
   "source": [
    "# Format the genre field\n",
    "formatted_genres = []\n",
    "genre_dict = dict()\n",
    "for g in book_summs['genre']:\n",
    "    subg = []\n",
    "    genre_dict = eval(g)\n",
    "    for k in genre_dict.keys():\n",
    "        subg.append(genre_dict[k])\n",
    "    formatted_genres.append(subg)\n",
    "book_summs['formatted_genre'] = formatted_genres\n",
    "print(book_summs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323441e",
   "metadata": {},
   "source": [
    "## Extract data to use for training & testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bada585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function adapted from midterm source code (PP1)\n",
    "def generate_vocab_map(df, cutoff=1):\n",
    "    vocab = {\"\": 0, \"UNK\": 1}\n",
    "    reversed_vocab = None\n",
    "    \n",
    "    # Iterate over the tokenized words in the dataset & construct a frequency map\n",
    "    vocab_count = dict()\n",
    "    uid = 2\n",
    "    for i in df['tokenized_title'].tolist():\n",
    "      # Iterate over the list of tokenized words from each summary\n",
    "      for t in i:\n",
    "        if t in vocab_count:\n",
    "            vocab_count[t] += 1\n",
    "        else:\n",
    "            vocab_count[t] = 1\n",
    "    for i in df['tokenized_summary'].tolist():\n",
    "        # Iterate over the list of tokensize words from each title\n",
    "        for t in i:\n",
    "            if t in vocab_count:\n",
    "                vocab_count[t] += 1\n",
    "            else:\n",
    "                vocab_count[t] = 1\n",
    "\n",
    "    # Ignore all words under the cutoff, give all others a unique id\n",
    "    for i in vocab_count.keys():\n",
    "        if vocab_count[i] > cutoff:\n",
    "            vocab[i] = uid\n",
    "            uid += 1\n",
    "    \n",
    "    reversed_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "    return vocab, reversed_vocab\n",
    "\n",
    "def generate_genre_map(genres):\n",
    "    genre_map = dict()\n",
    "    uid = 0\n",
    "    for g in genres:\n",
    "        genre_map[g] = uid\n",
    "        uid += 1\n",
    "    return genre_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc035ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique genres: 227\n",
      "{'Alternate history', 'Humour', 'Autobiographical novel', 'Anthology', 'Marketing', 'Speculative fiction', 'Psychology', 'Fantasy of manners', 'Social sciences', 'Picture book', 'Police procedural', 'Paranormal romance', 'Romantic comedy', 'Reference', 'Elizabethan romance', 'Supernatural', 'Regency romance', 'Existentialism', 'Comedy', 'Politics', 'Young adult literature', 'Wuxia', 'Youth', 'Invasion literature', 'Autobiographical comics', 'Lost World', 'Bildungsroman', 'Modernism', 'Future history', 'Political philosophy', 'Mathematics', 'Heroic fantasy', 'Pastiche', 'Ghost story', 'Absurdist fiction', 'Albino bias', 'New Weird', 'Fictional crossover', 'Biopunk', 'Serial', 'Post-holocaust', 'Edisonade', 'Religion', 'Scientific romance', 'Utopian fiction', 'American Gothic Fiction', 'Biography', 'Cookbook', 'Erotica', 'Ergodic literature', 'Superhero fiction', 'High fantasy', 'Space opera', 'Human extinction', 'Drama', 'Gay Themed', 'Comic science fiction', 'Bangsian fantasy', 'Subterranean fiction', 'Satire', 'Gay novel', 'Crime Fiction', 'Anthropology', 'Künstlerroman', 'Social criticism', 'Poetry', 'Conspiracy fiction', 'Urban fantasy', 'Sociology', 'Cabal', 'Literary realism', 'Naval adventure', 'Role-playing game', 'Low fantasy', 'Bit Lit', 'Experimental literature', 'Space western', 'Military science fiction', 'Gamebook', 'Chick lit', 'Non-fiction novel', 'Personal journal', 'Transhumanism', 'Western', 'Fantastique', 'Soft science fiction', 'Dark fantasy', 'Fable', 'Indian chick lit', 'Campus novel', 'Hardboiled', 'Time travel', 'New York Times Best Seller list', 'Tragicomedy', 'Western fiction', 'Historical novel', 'Historical romance', 'Black comedy', 'Social science fiction', 'Memoir', 'LGBT literature', 'Sword and sorcery', 'Alien invasion', 'Detective fiction', 'Mystery', 'Robinsonade', 'Comic fantasy', 'Literary criticism', 'Epic Science Fiction and Fantasy', 'Biographical novel', 'History', 'Colonial United States romance', 'Zombies in popular culture', 'Foreign legion', 'Suspense', \"Children's literature\", 'Comic novel', 'Postmodernism', 'Nature', 'Non-fiction', 'Contemporary fantasy', 'Self-help', 'Fairy tale', 'Neuroscience', 'Computer Science', 'Steampunk', 'Economics', 'Romance novel', 'Dying Earth subgenre', 'Locked room mystery', 'Postcyberpunk', 'Novel', 'Horror', 'Science fantasy', 'Transgender and transsexual fiction', 'Literary theory', 'Education', 'English public-school stories', 'Planetary romance', 'Philosophy', 'Parallel novel', 'Urban fiction', 'Photography', 'Industrial novel', 'Social novel', 'Autobiography', 'Catastrophic literature', 'Comics', 'Science', 'True crime', 'Comedy of manners', 'Fairytale fantasy', 'Collage', 'Sword and planet', 'Sea story', 'Treatise', 'Inspirational', 'Social commentary', 'Parody', 'Military history', 'Conspiracy', 'Magic realism', 'Medieval romance', 'Fantasy', 'Gothic fiction', 'Science Fiction', 'Morality play', 'Cyberpunk', 'Graphic novel', 'Spirituality', 'Coming of age', 'Historical fiction', 'Whodunit', 'Utopian and dystopian fiction', 'Polemic', 'Techno-thriller', 'Pornography', 'Essay', 'Travel', 'Religious text', 'Popular culture', 'Psychological novel', 'Spy fiction', 'Apocalyptic and post-apocalyptic fiction', 'Light novel', 'Play', 'Roman à clef', 'Literary fiction', 'Mashup', 'Chivalric romance', 'Comic book', 'Picaresque novel', 'Business', 'Historical fantasy', 'Farce', 'Anti-nuclear', 'Adventure', 'Creative nonfiction', 'Travel literature', 'Zombie', 'Georgian romance', \"Boys' school stories\", 'Prose', 'Juvenile fantasy', 'Prose poetry', 'Encyclopedia', 'Hard science fiction', 'Anti-war', 'War novel', 'Dystopia', 'Sports', 'Field guide', 'First-person narrative', 'Music', 'Vampire fiction', 'Adventure novel', 'Fiction', 'Short story', 'Novella', 'Epistolary novel', 'Popular science', 'Cozy', 'Feminist science fiction', 'School story', 'Metaphysics', 'Historical whodunnit', 'Thriller'}\n"
     ]
    }
   ],
   "source": [
    "genres = set()\n",
    "for x in book_summs['formatted_genre']:\n",
    "    genres.update(x)\n",
    "print('# of unique genres:', len(genres))\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ed7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reverse_vocab = generate_vocab_map(book_summs)\n",
    "genre_map = generate_genre_map(list(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ee4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tokenized_title  \\\n",
      "4503    [body, jonah, boyd]   \n",
      "11515           [magicians]   \n",
      "42        [heart, darkness]   \n",
      "7838   [machine, 's, child]   \n",
      "4392         [recognitions]   \n",
      "\n",
      "                                       tokenized_summary  \\\n",
      "4503   [anne, finds, manuscript, schemes, boyd, order...   \n",
      "11515  [main, character, ,, sir, charles, ravenstreet...   \n",
      "42     ['heart, darkness, ', opens, first, person, na...   \n",
      "7838   [end, life, world, come, ,, alec, checkerfield...   \n",
      "4392   [story, loosely, follows, life, wyatt, gwyon, ...   \n",
      "\n",
      "                              formatted_genre  \n",
      "4503                                [Fiction]  \n",
      "11515                   [Speculative fiction]  \n",
      "42           [Fiction, Novella, Roman à clef]  \n",
      "7838   [Science Fiction, Speculative fiction]  \n",
      "4392                                [Fiction]  \n",
      "            tokenized_title  \\\n",
      "4503    [body, jonah, boyd]   \n",
      "11515           [magicians]   \n",
      "42        [heart, darkness]   \n",
      "7838   [machine, 's, child]   \n",
      "4392         [recognitions]   \n",
      "\n",
      "                                       tokenized_summary  formatted_genre  \n",
      "4503   [anne, finds, manuscript, schemes, boyd, order...            [216]  \n",
      "11515  [main, character, ,, sir, charles, ravenstreet...              [5]  \n",
      "42     ['heart, darkness, ', opens, first, person, na...  [216, 218, 186]  \n",
      "7838   [end, life, world, come, ,, alec, checkerfield...         [165, 5]  \n",
      "4392   [story, loosely, follows, life, wyatt, gwyon, ...            [216]  \n"
     ]
    }
   ],
   "source": [
    "# We only care about tokenized and formatted data from the original dataset\n",
    "book_summs = book_summs.sample(frac=1)\n",
    "X = book_summs[['tokenized_title', 'tokenized_summary', 'formatted_genre']].copy()\n",
    "print(X.head())\n",
    "mapped_genres = []\n",
    "for x in X['formatted_genre']:\n",
    "    m = []\n",
    "    for g in x:\n",
    "        m.append(genre_map[g])\n",
    "    mapped_genres.append(m)\n",
    "X['formatted_genre'] = mapped_genres\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4a9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data\n",
    "from SummaryDataset import split_train_val_test\n",
    "X_train, X_val, X_test = split_train_val_test(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3150bb",
   "metadata": {},
   "source": [
    "## TODO: Review midterm PP1 for pytorch implementation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3949cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SummaryDataset import SummaryDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "train_dataset = SummaryDataset(train_vocab, X_train)\n",
    "val_dataset = SummaryDataset(train_vocab, X_val)\n",
    "test_dataset = SummaryDataset(train_vocab, X_test)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "test_sampler = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c79354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from SummaryDataset import collate_fn\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "077d381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GenreClassifier import ClassificationModel\n",
    "\n",
    "model = None\n",
    "model = ClassificationModel(vocab_size=len(train_vocab.keys()), embedding_dim=300, hidden_dim=1, output_dim=len(genres), num_layers=1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f4eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "criterion, optimizer = None, None\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b089e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# returns the total loss calculated from criterion\n",
    "def train_loop(model, criterion, iterator):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(iterator):\n",
    "        y_pred = model(x).round()\n",
    "        loss = criterion(torch.flatten(y_pred),torch.tensor(y, dtype=torch.float))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "    return total_loss\n",
    "\n",
    "# returns:\n",
    "# - true: a Python boolean array of all the ground truth values\n",
    "#         taken from the dataset iterator\n",
    "# - pred: a Python boolean array of all model predictions.\n",
    "def val_loop(model, criterion, iterator):\n",
    "    true, pred = [], []\n",
    "    for x, y in tqdm(iterator):\n",
    "        for t in y:\n",
    "            true.append(t)\n",
    "        y_pred = model(x).round()\n",
    "        for p in y_pred:\n",
    "            pred.append(p)\n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c202152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/81 [00:00<?, ?it/s]/Users/cindyzastudil/Documents/cis5590-project/SummaryDataset.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_t = torch.tensor(x, dtype=torch.long)\n",
      "  0%|                                                    | 0/81 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 227)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from src.eval_utils import binary_macro_f1, accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m true, pred \u001b[38;5;241m=\u001b[39m \u001b[43mval_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(binary_macro_f1(true, pred)) # TODO: CHANGE METRIC CALCULATIONS\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#print(accuracy(true, pred)) # TODO: CHANGE METRIC CALCULATIONS\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "Cell \u001b[0;32mIn[15], line 24\u001b[0m, in \u001b[0;36mval_loop\u001b[0;34m(model, criterion, iterator)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[1;32m     23\u001b[0m     true\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m---> 24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m y_pred:\n\u001b[1;32m     26\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/Documents/cis5590-project/GenreClassifier.py:58\u001b[0m, in \u001b[0;36mClassificationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m x, (h0, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(torch\u001b[38;5;241m.\u001b[39mcat((h0[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,:,:], h0[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:]), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 58\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/activation.py:1198\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:1512\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1514\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 227)"
     ]
    }
   ],
   "source": [
    "#from src.eval_utils import binary_macro_f1, accuracy\n",
    "true, pred = val_loop(model, criterion, val_iterator)\n",
    "#print(binary_macro_f1(true, pred)) # TODO: CHANGE METRIC CALCULATIONS\n",
    "#print(accuracy(true, pred)) # TODO: CHANGE METRIC CALCULATIONS\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eda085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
