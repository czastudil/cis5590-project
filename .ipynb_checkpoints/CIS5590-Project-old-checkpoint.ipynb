{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853720bd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac3cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cindyzastudil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/cindyzastudil/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cindyzastudil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d4398",
   "metadata": {},
   "source": [
    "## Read in the CMU Book Summary Dataset\n",
    "\n",
    "The CMU Book Summary Dataset is a collection of 16,559 different book summaries extracted from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48849602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       title  \\\n",
      "0                                Animal Farm   \n",
      "1                         A Clockwork Orange   \n",
      "2                                 The Plague   \n",
      "3  An Enquiry Concerning Human Understanding   \n",
      "4                       A Fire Upon the Deep   \n",
      "\n",
      "                                               genre  \\\n",
      "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
      "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
      "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
      "3                                                NaN   \n",
      "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
      "\n",
      "                                             summary  \n",
      "0   Old Major, the old boar on the Manor Farm, ca...  \n",
      "1   Alex, a teenager living in near-future Englan...  \n",
      "2   The text of The Plague is divided into five p...  \n",
      "3   The argument of the Enquiry proceeds by a ser...  \n",
      "4   The novel posits that space around the Milky ...  \n"
     ]
    }
   ],
   "source": [
    "# Read in the data and add columns to the dataframe\n",
    "book_summs = pd.read_csv('data/booksummaries.txt', header=None, sep='\\t')\n",
    "book_summs.columns =['wikipedia_article_id', 'freebase_id', 'title', 'author', 'pub_date', 'genre', 'summary']\n",
    "\n",
    "# Remove extraneous features - wikipedia_article_id, freebase_id, author, pub_date\n",
    "book_summs = book_summs.drop(labels=['wikipedia_article_id', 'freebase_id', 'author', 'pub_date'], axis=1)\n",
    "print(book_summs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e6030",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a37027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code taken from fast-bert\n",
    "def spec_add_spaces(t: str) -> str:\n",
    "    \"Add spaces around / and # in `t`. \\n\"\n",
    "    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\n",
    "\n",
    "def rm_useless_spaces(t: str) -> str:\n",
    "    \"Remove multiple spaces in `t`.\"\n",
    "    return re.sub(\" {2,}\", \" \", t)\n",
    "\n",
    "def replace_multi_newline(t: str) -> str:\n",
    "    return re.sub(r\"(\\n(\\s)*){2,}\", \"\\n\", t)\n",
    "\n",
    "def clean_text(input_text):\n",
    "    text = replace_multi_newline(input_text)\n",
    "    text = spec_add_spaces(text)\n",
    "    text = rm_useless_spaces(text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f4dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset before preprocessing: 16559\n",
      "Size of dataset after removing missing genres: 12841\n",
      "Size of dataset after removing missing titles: 12841\n",
      "Size of dataset after removing missing summaries: 12841\n",
      "Size of dataset after preprocessing: 12841\n",
      "                            title  \\\n",
      "0                     Animal Farm   \n",
      "1              A Clockwork Orange   \n",
      "2                      The Plague   \n",
      "4            A Fire Upon the Deep   \n",
      "5  All Quiet on the Western Front   \n",
      "\n",
      "                                               genre  \\\n",
      "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
      "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
      "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
      "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
      "5  {\"/m/098tmk\": \"War novel\", \"/m/016lj8\": \"Roman...   \n",
      "\n",
      "                                             summary          tokenized_title  \\\n",
      "0   Old Major, the old boar on the Manor Farm, ca...           [animal, farm]   \n",
      "1   Alex, a teenager living in near-future Englan...      [clockwork, orange]   \n",
      "2   The text of The Plague is divided into five p...                 [plague]   \n",
      "4   The novel posits that space around the Milky ...       [fire, upon, deep]   \n",
      "5   The book tells the story of Paul Bäumer, a Ge...  [quiet, western, front]   \n",
      "\n",
      "                                   tokenized_summary  \n",
      "0  [old, major, ,, old, boar, manor, farm, ,, cal...  \n",
      "1  [alex, ,, teenager, living, near-future, engla...  \n",
      "2  [text, plague, divided, five, parts, ., town, ...  \n",
      "4  [novel, posits, space, around, milky, way, div...  \n",
      "5  [book, tells, story, paul, bäumer, ,, german, ...  \n"
     ]
    }
   ],
   "source": [
    "print('Size of dataset before preprocessing:', len(book_summs))\n",
    "\n",
    "# Remove any books which don't have genres\n",
    "book_summs.dropna(subset=['genre'], inplace=True)\n",
    "\n",
    "print('Size of dataset after removing missing genres:', len(book_summs))\n",
    "\n",
    "# Remove any books which don't have titles\n",
    "book_summs.dropna(subset=['title'], inplace=True)\n",
    "\n",
    "print('Size of dataset after removing missing titles:', len(book_summs))\n",
    "\n",
    "# Remove any books which don't have summaries\n",
    "book_summs.dropna(subset=['summary'], inplace=True)\n",
    "\n",
    "print('Size of dataset after removing missing summaries:', len(book_summs))\n",
    "print('Size of dataset after preprocessing:', len(book_summs))\n",
    "\n",
    "# Tokenize titles & convert to lower case - add to tokenized_title column\n",
    "book_summs['tokenized_title'] = book_summs['title'].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "\n",
    "# Tokenize summaries & convert to lower case - add to tokenized_summary column\n",
    "book_summs['tokenized_summary'] = book_summs['summary'].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "\n",
    "# Remove all stop words from all summaries & titles\n",
    "stop = stopwords.words('english')\n",
    "book_summs['tokenized_summary'] = book_summs['tokenized_summary'].apply(lambda x: [word for word in x if word not in (stop)])\n",
    "book_summs['tokenized_title'] = book_summs['tokenized_title'].apply(lambda x: [word for word in x if word not in (stop)])\n",
    "    \n",
    "print(book_summs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6029cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            title  \\\n",
      "0                     Animal Farm   \n",
      "1              A Clockwork Orange   \n",
      "2                      The Plague   \n",
      "4            A Fire Upon the Deep   \n",
      "5  All Quiet on the Western Front   \n",
      "\n",
      "                                               genre  \\\n",
      "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
      "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
      "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
      "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
      "5  {\"/m/098tmk\": \"War novel\", \"/m/016lj8\": \"Roman...   \n",
      "\n",
      "                                             summary          tokenized_title  \\\n",
      "0   Old Major, the old boar on the Manor Farm, ca...           [animal, farm]   \n",
      "1   Alex, a teenager living in near-future Englan...      [clockwork, orange]   \n",
      "2   The text of The Plague is divided into five p...                 [plague]   \n",
      "4   The novel posits that space around the Milky ...       [fire, upon, deep]   \n",
      "5   The book tells the story of Paul Bäumer, a Ge...  [quiet, western, front]   \n",
      "\n",
      "                                   tokenized_summary  \\\n",
      "0  [old, major, ,, old, boar, manor, farm, ,, cal...   \n",
      "1  [alex, ,, teenager, living, near-future, engla...   \n",
      "2  [text, plague, divided, five, parts, ., town, ...   \n",
      "4  [novel, posits, space, around, milky, way, div...   \n",
      "5  [book, tells, story, paul, bäumer, ,, german, ...   \n",
      "\n",
      "                                     formatted_genre  \n",
      "0  [Roman à clef, Satire, Children's literature, ...  \n",
      "1  [Science Fiction, Novella, Speculative fiction...  \n",
      "2  [Existentialism, Fiction, Absurdist fiction, N...  \n",
      "4  [Hard science fiction, Science Fiction, Specul...  \n",
      "5                          [War novel, Roman à clef]  \n"
     ]
    }
   ],
   "source": [
    "# Format the genre field\n",
    "formatted_genres = []\n",
    "genre_dict = dict()\n",
    "for g in book_summs['genre']:\n",
    "    subg = []\n",
    "    genre_dict = eval(g)\n",
    "    for k in genre_dict.keys():\n",
    "        subg.append(genre_dict[k])\n",
    "    formatted_genres.append(subg)\n",
    "book_summs['formatted_genre'] = formatted_genres\n",
    "print(book_summs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323441e",
   "metadata": {},
   "source": [
    "## Extract data to use for training & testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bada585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function adapted from midterm source code (PP1)\n",
    "def generate_vocab_map(df, cutoff=1):\n",
    "    vocab = {\"\": 0, \"UNK\": 1}\n",
    "    reversed_vocab = None\n",
    "    \n",
    "    # Iterate over the tokenized words in the dataset & construct a frequency map\n",
    "    vocab_count = dict()\n",
    "    uid = 2\n",
    "    for i in df['tokenized_title'].tolist():\n",
    "      # Iterate over the list of tokenized words from each summary\n",
    "      for t in i:\n",
    "        if t in vocab_count:\n",
    "            vocab_count[t] += 1\n",
    "        else:\n",
    "            vocab_count[t] = 1\n",
    "    for i in df['tokenized_summary'].tolist():\n",
    "        # Iterate over the list of tokensize words from each title\n",
    "        for t in i:\n",
    "            if t in vocab_count:\n",
    "                vocab_count[t] += 1\n",
    "            else:\n",
    "                vocab_count[t] = 1\n",
    "\n",
    "    # Ignore all words under the cutoff, give all others a unique id\n",
    "    for i in vocab_count.keys():\n",
    "        if vocab_count[i] > cutoff:\n",
    "            vocab[i] = uid\n",
    "            uid += 1\n",
    "    \n",
    "    reversed_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "    return vocab, reversed_vocab\n",
    "\n",
    "def generate_genre_map(genres):\n",
    "    genre_map = dict()\n",
    "    uid = 0\n",
    "    for g in genres:\n",
    "        genre_map[g] = uid\n",
    "        uid += 1\n",
    "    return genre_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc035ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique genres: 227\n",
      "{'Coming of age', 'Comic novel', 'Contemporary fantasy', 'Economics', 'Crime Fiction', 'Hardboiled', 'New York Times Best Seller list', 'Cozy', 'Military science fiction', 'War novel', 'Comics', 'Magic realism', 'Spy fiction', 'Picaresque novel', 'Photography', 'Fable', 'Comic science fiction', 'Utopian and dystopian fiction', 'Chick lit', 'Juvenile fantasy', 'Existentialism', 'Prose poetry', 'Zombie', 'Ghost story', 'Low fantasy', 'LGBT literature', 'Police procedural', 'Postmodernism', 'Naval adventure', 'Creative nonfiction', 'Graphic novel', 'Psychological novel', 'Bit Lit', 'Metaphysics', 'Epic Science Fiction and Fantasy', 'Polemic', 'Prose', 'Play', 'Short story', 'Travel', 'Popular culture', 'Anti-war', 'Cabal', 'Non-fiction novel', 'Urban fiction', 'Colonial United States romance', 'Drama', 'Experimental literature', 'Black comedy', 'Locked room mystery', 'Absurdist fiction', 'Thriller', 'Roman à clef', 'Political philosophy', 'Mashup', 'Dark fantasy', 'Georgian romance', 'Detective fiction', 'Military history', 'Serial', 'Transgender and transsexual fiction', 'History', 'Gothic fiction', 'Reference', 'Zombies in popular culture', 'Künstlerroman', 'Literary criticism', 'Marketing', 'Regency romance', 'Elizabethan romance', 'Hard science fiction', 'Science', 'Space opera', 'Science Fiction', 'Wuxia', 'Historical romance', 'Biopunk', 'Fantastique', 'Dystopia', 'Cyberpunk', 'Historical whodunnit', 'Anthropology', 'Tragicomedy', 'Social commentary', 'American Gothic Fiction', 'Bildungsroman', 'Human extinction', 'Lost World', 'Field guide', 'Sword and sorcery', 'Pastiche', 'Adventure', 'Sword and planet', 'Business', 'Music', 'True crime', 'Politics', 'Literary theory', 'Feminist science fiction', 'Postcyberpunk', 'Industrial novel', 'Gay Themed', 'Novella', 'Historical novel', 'Literary fiction', 'Self-help', 'Romantic comedy', 'Poetry', 'Utopian fiction', 'Anti-nuclear', 'Autobiographical comics', 'Space western', 'Bangsian fantasy', 'Nature', 'Anthology', 'Religion', 'Fantasy of manners', 'Sports', 'Novel', 'Fairytale fantasy', 'Soft science fiction', 'Alternate history', 'Psychology', 'Chivalric romance', 'Youth', 'Literary realism', 'Neuroscience', 'Morality play', 'Urban fantasy', 'Mathematics', 'Speculative fiction', 'Apocalyptic and post-apocalyptic fiction', 'Travel literature', 'Campus novel', 'Biography', 'Social science fiction', 'Inspirational', 'Conspiracy', 'Western', \"Children's literature\", \"Boys' school stories\", 'Spirituality', 'Edisonade', 'Future history', 'Collage', 'Sea story', 'Comedy', 'Fantasy', 'Albino bias', 'Gamebook', 'Romance novel', 'Gay novel', 'Social novel', 'Fiction', 'Encyclopedia', 'Popular science', 'Comic book', 'Medieval romance', 'Fairy tale', 'Adventure novel', 'Personal journal', 'Scientific romance', 'Parody', 'Historical fiction', 'Autobiographical novel', 'Satire', 'Heroic fantasy', 'High fantasy', 'Pornography', 'Horror', 'Epistolary novel', 'Catastrophic literature', 'Robinsonade', 'Alien invasion', 'Whodunit', 'Vampire fiction', 'Transhumanism', 'Cookbook', 'Paranormal romance', 'Post-holocaust', 'Parallel novel', 'Science fantasy', 'Mystery', 'Biographical novel', 'Religious text', 'Farce', 'Historical fantasy', 'Fictional crossover', 'Dying Earth subgenre', 'Subterranean fiction', 'Essay', 'Comic fantasy', 'Indian chick lit', 'Techno-thriller', 'Picture book', 'Young adult literature', 'First-person narrative', 'Treatise', 'Invasion literature', 'Suspense', 'New Weird', 'Steampunk', 'Ergodic literature', 'Social criticism', 'Sociology', 'Conspiracy fiction', 'Social sciences', 'Philosophy', 'Modernism', 'Humour', 'Memoir', 'Planetary romance', 'Foreign legion', 'Light novel', 'Autobiography', 'English public-school stories', 'Non-fiction', 'Western fiction', 'School story', 'Computer Science', 'Time travel', 'Erotica', 'Supernatural', 'Role-playing game', 'Superhero fiction', 'Comedy of manners', 'Education'}\n"
     ]
    }
   ],
   "source": [
    "genres = set()\n",
    "for x in book_summs['formatted_genre']:\n",
    "    genres.update(x)\n",
    "print('# of unique genres:', len(genres))\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ed7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reverse_vocab = generate_vocab_map(book_summs)\n",
    "genre_map = generate_genre_map(list(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ee4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    tokenized_title  \\\n",
      "995                 [black, dahlia]   \n",
      "6345               [ordinary, jack]   \n",
      "8355             [fourth, mansions]   \n",
      "10398                     [camp, x]   \n",
      "15184  [necroscope, iii, :, source]   \n",
      "\n",
      "                                       tokenized_summary  \\\n",
      "995    [june, ,, 1943, patrol, officer, dwight, ``, b...   \n",
      "6345   [depressed, 'ordinary, ', child, talented, fam...   \n",
      "8355   [fourth, mansions, inspired, teresa, ávila, 's...   \n",
      "10398  [11-year-old, george, older, brother, jack, mo...   \n",
      "15184  [series, starts, explore, origins, wamphyri, m...   \n",
      "\n",
      "                                         formatted_genre  \n",
      "995    [Crime Fiction, Mystery, Novel, Fiction, Suspe...  \n",
      "6345                    [Children's literature, Fiction]  \n",
      "8355   [Science Fiction, Speculative fiction, Fantasy...  \n",
      "10398  [Mystery, Children's literature, Young adult l...  \n",
      "15184                 [Science Fiction, Adventure novel]  \n",
      "                    tokenized_title  \\\n",
      "995                 [black, dahlia]   \n",
      "6345               [ordinary, jack]   \n",
      "8355             [fourth, mansions]   \n",
      "10398                     [camp, x]   \n",
      "15184  [necroscope, iii, :, source]   \n",
      "\n",
      "                                       tokenized_summary  \\\n",
      "995    [june, ,, 1943, patrol, officer, dwight, ``, b...   \n",
      "6345   [depressed, 'ordinary, ', child, talented, fam...   \n",
      "8355   [fourth, mansions, inspired, teresa, ávila, 's...   \n",
      "10398  [11-year-old, george, older, brother, jack, mo...   \n",
      "15184  [series, starts, explore, origins, wamphyri, m...   \n",
      "\n",
      "                formatted_genre  \n",
      "995     [4, 182, 118, 153, 199]  \n",
      "6345                 [139, 153]  \n",
      "8355        [73, 130, 147, 153]  \n",
      "10398  [182, 139, 195, 153, 12]  \n",
      "15184                 [73, 159]  \n"
     ]
    }
   ],
   "source": [
    "# We only care about tokenized and formatted data from the original dataset\n",
    "book_summs = book_summs.sample(frac=1)\n",
    "X = book_summs[['tokenized_title', 'tokenized_summary', 'formatted_genre']].copy()\n",
    "print(X.head())\n",
    "mapped_genres = []\n",
    "for x in X['formatted_genre']:\n",
    "    m = []\n",
    "    for g in x:\n",
    "        m.append(genre_map[g])\n",
    "    mapped_genres.append(m)\n",
    "X['formatted_genre'] = mapped_genres\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4a9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data\n",
    "from SummaryDataset import split_train_val_test\n",
    "X_train, X_val, X_test = split_train_val_test(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3150bb",
   "metadata": {},
   "source": [
    "## TODO: Review midterm PP1 for pytorch implementation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3949cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SummaryDataset import SummaryDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "train_dataset = SummaryDataset(train_vocab, X_train)\n",
    "val_dataset = SummaryDataset(train_vocab, X_val)\n",
    "test_dataset = SummaryDataset(train_vocab, X_test)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "test_sampler = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c79354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from SummaryDataset import collate_fn\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077d381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GenreClassifier import ClassificationModel\n",
    "\n",
    "model = None\n",
    "model = ClassificationModel(vocab_size=len(train_vocab.keys()), embedding_dim=300, hidden_dim=1, output_dim=len(genres), num_layers=1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f4eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "criterion, optimizer = None, None\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b089e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# returns the total loss calculated from criterion\n",
    "def train_loop(model, criterion, iterator):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(iterator):\n",
    "        y_pred = model(x).round()\n",
    "        loss = criterion(torch.flatten(y_pred),torch.tensor(y, dtype=torch.float))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "    return total_loss\n",
    "\n",
    "# returns:\n",
    "# - true: a Python boolean array of all the ground truth values\n",
    "#         taken from the dataset iterator\n",
    "# - pred: a Python boolean array of all model predictions.\n",
    "def val_loop(model, criterion, iterator):\n",
    "    true, pred = [], []\n",
    "    for x, y in tqdm(iterator):\n",
    "        for t in y:\n",
    "            true.append(t)\n",
    "        y_pred = model(x).round()\n",
    "        for p in y_pred:\n",
    "            pred.append(p)\n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.eval_utils import binary_macro_f1, accuracy\n",
    "true, pred = val_loop(model, criterion, val_iterator)\n",
    "#print(binary_macro_f1(true, pred)) # TODO: CHANGE METRIC CALCULATIONS\n",
    "#print(accuracy(true, pred)) # TODO: CHANGE METRIC CALCULATIONS\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eda085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
